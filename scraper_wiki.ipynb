{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH4FzDeT1vIc1wSsUsjiaN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MklsHMVmTzkO",
        "outputId": "f7b1c349-3358-4368-9729-cf273c8a06a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=340ca8652df5077992a5cd661a45379cd3a98a2ec3046396ac9d721375b03d8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the wikipedia library\n",
        "import wikipedia\n",
        "\n",
        "# Search for a page title\n",
        "page = wikipedia.page(\"Artificial intelligence\")\n",
        "\n",
        "# Get the page summary\n",
        "summary = page.summary\n",
        "\n",
        "# Print the summary\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wY_rGr2Ub3s",
        "outputId": "3acbaaeb-134a-4ef5-8289-2057601a20db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence (AI) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by humans or by other animals. Example tasks in which this is done include speech recognition, computer vision, translation between (natural) languages, as well as other mappings of inputs.\n",
            "AI applications include advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), automated decision-making, and competing at the highest level in strategic game systems (such as chess and Go).As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.Artificial intelligence was founded as an academic discipline in 1956, and in the years since it has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success, and renewed funding. AI research has tried and discarded many different approaches, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge, and imitating animal behavior. In the first decades of the 21st century, highly mathematical and statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and the ability to move and manipulate objects. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals. To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability, and economics. AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.\n",
            "The field was founded on the assumption that human intelligence \"can be so precisely described that a machine can be made to simulate it\". This raised philosophical arguments about the mind and the ethical consequences of creating artificial beings endowed with human-like intelligence; these issues have previously been explored by myth, fiction (science fiction), and philosophy since antiquity. Computer scientists and philosophers have since suggested that AI may become an existential risk to humanity if its rational capacities are not steered towards goals beneficial to humankind. The term artificial intelligence has also been criticized for overhyping AI's true technological capabilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "import random\n",
        "\n",
        "\n",
        "def scrape_page(page_title):\n",
        "  # Try to get the page object\n",
        "  try:\n",
        "    page = wikipedia.page(page_title)\n",
        "  # If the page does not exist, return None\n",
        "  except wikipedia.exceptions.PageError:\n",
        "    return None\n",
        "\n",
        "  summary = page.summary\n",
        "  # Get the page links\n",
        "  links = page.links\n",
        "\n",
        "  return (summary, links)\n",
        "\n",
        "\n",
        "def write_summary(summary, file):\n",
        "\n",
        "  with open(file, \"a\") as f:\n",
        "\n",
        "    f.write(summary + \"\\n\")\n",
        "\n",
        "# Define a list of starting pages\n",
        "start_pages = [\"Artificial intelligence\", \"Machine learning\", \"Deep learning\", \"Natural language processing\", \"Computer vision\"]\n",
        "\n",
        "# Define a set of visited pages\n",
        "visited_pages = set()\n",
        "\n",
        "# Define a counter for scraped pages\n",
        "counter = 0\n",
        "\n",
        "# Define the maximum number of pages to scrape\n",
        "max_pages = 10\n",
        "\n",
        "# Define the name of the output file\n",
        "output_file = \"scraped_pages.txt\"\n",
        "\n",
        "\n",
        "while counter < max_pages and start_pages:\n",
        "\n",
        "  current_page = random.choice(start_pages)\n",
        "\n",
        "  start_pages.remove(current_page)\n",
        "  # Check if the current page is already visited\n",
        "  if current_page in visited_pages:\n",
        "    # Skip this page and continue the loop\n",
        "    continue\n",
        "\n",
        "  result = scrape_page(current_page)\n",
        "\n",
        "  if result:\n",
        "\n",
        "    summary, links = result\n",
        "\n",
        "    write_summary(summary, output_file)\n",
        "\n",
        "    visited_pages.add(current_page)\n",
        "    # Increment the counter by one\n",
        "    counter += 1\n",
        "\n",
        "    print(f\"Scraped {counter} pages: {current_page}\")\n",
        "\n",
        "    start_pages.extend(random.sample(links, min(5, len(links))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9xJZnwaUe9z",
        "outputId": "130d07de-8595-45b8-c951-8aca304f7392"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 1 pages: Artificial intelligence\n",
            "Scraped 2 pages: Optimization (mathematics)\n",
            "Scraped 3 pages: Decision-making\n",
            "Scraped 4 pages: Euclidean geometry\n",
            "Scraped 5 pages: Automated decision support\n",
            "Scraped 6 pages: Robotics suite\n",
            "Scraped 7 pages: DeSanctis, Gerardine\n",
            "Scraped 8 pages: Internet\n",
            "Scraped 9 pages: Electronic voting\n",
            "Scraped 10 pages: Ticket (election)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1gYuS3uvHEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}